# íŒ¨í‚¤ì§€ ì„¤ì¹˜
import cv2
import time
import numpy as np
import json
from datetime import datetime
import os
import pandas as pd

# ì‚¬ìš©ì ì •ì˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
from ai_model.hand_tracker import HandTracker
from ai_model.arm_logic import is_pronator_drift_thumb_pinky, is_arm_dropped
from utils.draw_korean import draw_korean_text
from utils.result_saver import save_result_csv

# ê°€ì´ë“œ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° (ì•ŒíŒŒ ì±„ë„ í¬í•¨)
guide = cv2.imread("guide.png", cv2.IMREAD_UNCHANGED)

# íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ì˜ìƒì— ì˜¤ë²„ë ˆì´í•˜ëŠ” í•¨ìˆ˜
def overlay_image_alpha(img, img_overlay, pos, alpha_mask):
    x, y = pos
    h, w = img_overlay.shape[:2]
    # ì´ë¯¸ì§€ê°€ í™”ë©´ ë°–ìœ¼ë¡œ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ìë¥´ê¸°
    if x + w > img.shape[1] or y + h > img.shape[0]:
        w = min(w, img.shape[1] - x)
        h = min(h, img.shape[0] - y)
        img_overlay = img_overlay[:h, :w]
        alpha_mask = alpha_mask[:h, :w]
    # RGB ì±„ë„ë³„ë¡œ ì•ŒíŒŒ ë¸”ëœë”© ì ìš©
    for c in range(3):
        img[y:y+h, x:x+w, c] = (
            alpha_mask * img_overlay[:, :, c] +
            (1 - alpha_mask) * img[y:y+h, x:x+w, c]
        )

# Mediapipe ê¸°ë°˜ í•¸ë“œíŠ¸ë˜ì»¤ ì´ˆê¸°í™”
tracker = HandTracker()

# ì›¹ìº  ìº¡ì³ ì„¤ì •
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)

# ì¸¡ì •ì— í•„ìš”í•œ ë³€ìˆ˜ ì´ˆê¸°í™”
start_time = None
measuring_started = False
first_data, last_data = {}, {}
first_y_data, last_y_data = {}, {}
in_guide_start_time = None

print("ì–‘ì†ì´ ì •í•´ì§„ ë°•ìŠ¤ì— ë“¤ì–´ì˜¤ë©´ 10ì´ˆê°„ ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

# ì–‘ì† ìœ„ì¹˜ë¥¼ í™•ì¸í•  ê¸°ì¤€ ë°•ìŠ¤ ì˜ì—­ ì •ì˜
left_box = ((150, 400), (450, 650))
right_box = ((850, 400), (1150, 650))

# ì†ê°€ë½ ìœ„ì¹˜ê°€ ë°•ìŠ¤ ì•ˆì— ë“¤ì–´ì™”ëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
def is_in_box(point, box):
    x, y = point
    (x1, y1), (x2, y2) = box
    return x1 <= x <= x2 and y1 <= y <= y2

while True:
    success, img = cap.read()
    if not success:
        break

    img = cv2.flip(img, 1)  # ì¢Œìš°ë°˜ì „ (ê±°ìš¸ëª¨ë“œ)
    height, width, _ = img.shape
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    result = tracker.process(img_rgb)
    current_time = time.time()

    # ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
    cv2.rectangle(img, left_box[0], left_box[1], (0, 0, 255), 2)
    cv2.rectangle(img, right_box[0], right_box[1], (0, 0, 255), 2)

    # í•˜ë‹¨ ê°€ì´ë“œ ì´ë¯¸ì§€ ì˜¤ë²„ë ˆì´
    if guide is not None and guide.shape[2] == 4:
        overlay_rgb = guide[:, :, :3]
        overlay_alpha = guide[:, :, 3] / 255.0
        pos_x = (width - guide.shape[1]) // 2
        pos_y = height - guide.shape[0]
        overlay_image_alpha(img, overlay_rgb, (pos_x, pos_y), overlay_alpha)
    
    # ì†ì´ ê°ì§€ë˜ì—ˆì„ ê²½ìš°
    if result.multi_hand_landmarks and result.multi_handedness:
        middle_fingers = {"Left": None, "Right": None}
        # ê° ì†ì˜ ì¤‘ì§€ TIP ì¢Œí‘œ ì €ì¥
        for i, hand_landmarks in enumerate(result.multi_hand_landmarks):
            hand_label = result.multi_handedness[i].classification[0].label
            mid_tip = hand_landmarks.landmark[12]
            cx, cy = int(mid_tip.x * width), int(mid_tip.y * height)
            middle_fingers[hand_label] = (cx, cy)
        
        # ì¸¡ì • ì‹œì‘ ì¡°ê±´: ì–‘ì†ì´ ë°•ìŠ¤ ì•ˆì— 3ì´ˆê°„ ìœ ì§€ë˜ì—ˆì„ ë•Œ
        if not measuring_started and middle_fingers["Left"] and middle_fingers["Right"]:
            in_left = is_in_box(middle_fingers["Left"], left_box)
            in_right = is_in_box(middle_fingers["Right"], right_box)

            if in_left and in_right:
                if in_guide_start_time is None:
                    in_guide_start_time = current_time
                elif current_time - in_guide_start_time > 3:
                    start_time = current_time
                    measuring_started = True
                    print("ì¸¡ì • ì‹œì‘!")
            else:
                in_guide_start_time = None

        # ì¸¡ì • ì¤‘ ì´ë¼ë©´ ì‹œê°„ í‘œì‹œ
        if measuring_started:
            elapsed = current_time - start_time
            elapsed_int = int(elapsed)
            text = f"ì¸¡ì • ì‹œê°„: {elapsed_int} / 10ì´ˆ"
            position = ((width - len(text) * 16) // 2, height - 50)
            img = draw_korean_text(img, text, position)

        # ì†ê°€ë½ ì¢Œí‘œ ë° ë°ì´í„°ë¥¼ ì¶”ì¶œ
        for i, hand_landmarks in enumerate(result.multi_hand_landmarks):
            hand_label = result.multi_handedness[i].classification[0].label
            thumb_x = hand_landmarks.landmark[4].x
            pinky_x = hand_landmarks.landmark[20].x
            y_list = [hand_landmarks.landmark[idx].y for idx in tracker.fingertip_indices]

            # ì†ê°€ë½ TIP ì‹œê°í™”
            for idx in tracker.fingertip_indices:
                lm = hand_landmarks.landmark[idx]
                cx, cy = int(lm.x * width), int(lm.y * height)
                cv2.circle(img, (cx, cy), 6, (255, 0, 0), cv2.FILLED)

            # ì¸¡ì • ì‹œì ë³„ë¡œ ì¢Œí‘œ ì €ì¥ (3ì´ˆ, 10ì´ˆ ê¸°ì¤€)
            if measuring_started:
                elapsed = current_time - start_time
                if 2.5 < elapsed < 3.5:
                    mcp5_x = hand_landmarks.landmark[5].x
                    mcp13_x = hand_landmarks.landmark[13].x
                    first_data[hand_label] = (thumb_x, pinky_x, mcp5_x, mcp13_x)
                    first_y_data[hand_label] = y_list
                elif 9.5 < elapsed < 10.5:
                    mcp5_x = hand_landmarks.landmark[5].x
                    mcp13_x = hand_landmarks.landmark[13].x
                    last_data[hand_label] = (thumb_x, pinky_x, mcp5_x, mcp13_x)
                    last_y_data[hand_label] = y_list
    else:
        # ì† ë¯¸ì¸ì‹ ì‹œ ë©”ì‹œì§€ ì¶œë ¥
        if not measuring_started:
            img = draw_korean_text(img, "ì† ì¸ì‹ ëŒ€ê¸° ì¤‘...", (width // 2 - 150, height - 50))

    if not measuring_started:
        draw_korean_text(img, "ì–‘ì†ì„ ê²€ì • ë°•ìŠ¤ ì•ˆì— 3ì´ˆê°„ ìœ ì§€í•˜ì„¸ìš”", (width // 2 - 250, 50), font_size=28)

    cv2.imshow("Pronator Drift Detection", img)
    
    # 'q'ë¥¼ ëˆ„ë¥´ê±°ë‚˜ 10ì´ˆ ê²½ê³¼ ì‹œ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == ord('q') or (measuring_started and (current_time - start_time > 11)):
        break

cap.release()
cv2.destroyAllWindows()

# ---------------- ì¸¡ì • ê²°ê³¼ ë¶„ì„ ----------------------------

# ì´ˆê¸°ê°’
left_drift = right_drift = left_fall = right_fall = False
result_data = {"timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

# ì™¼ì† ê²°ê³¼ ë¶„ì„
if "Left" in first_data and "Left" in last_data:
    t1, p1, m5_1, m13_1 = first_data["Left"]
    t2, p2, m5_2, m13_2 = last_data["Left"]

    left_drift = is_pronator_drift_thumb_pinky("Left", m5_1, m13_1, m5_2, m13_2)
    left_fall, left_diffs = is_arm_dropped(first_y_data["Left"], last_y_data["Left"])
    left_slope_diff = round(abs((m13_2 - m5_2) - (m13_1 - m5_1)), 3)

    result_data["Left"] = {
        "slope_diff": left_slope_diff,
        "y_diffs": [round(d, 4) for d in left_diffs],
        "drift_detected": left_drift,
        "drop_detected": left_fall
    }

# ì˜¤ë¥¸ì† ê²°ê³¼ ë¶„ì„
if "Right" in first_data and "Right" in last_data:
    t1, p1, m5_1, m13_1 = first_data["Right"]
    t2, p2, m5_2, m13_2 = last_data["Right"]

    right_drift = is_pronator_drift_thumb_pinky("Right", m5_1, m13_1, m5_2, m13_2)
    right_fall, right_diffs = is_arm_dropped(first_y_data["Right"], last_y_data["Right"])
    right_slope_diff = round(abs((m13_2 - m5_2) - (m13_1 - m5_1)), 3)

    result_data["Right"] = {
        "slope_diff": right_slope_diff,
        "y_diffs": [round(d, 4) for d in right_diffs],
        "drift_detected": right_drift,
        "drop_detected": right_fall
    }

# ìµœì¢… ì§„ë‹¨ íŒë‹¨
if (left_drift or left_fall) ^ (right_drift or right_fall):
    result_data["final_diagnosis"] = "detected"
elif (left_drift or left_fall) and (right_drift or right_fall):
    result_data["final_diagnosis"] = "both_abnormal"
else:
    result_data["final_diagnosis"] = "normal"

# CSV ìƒì„±
save_result_csv(result_data)

# í„°ë¯¸ë„ ì¶œë ¥
if "Left" in result_data:
    left = result_data["Left"]
    print(f"[Left] y ë³€í™”ëŸ‰: {left['y_diffs']} â†’ í•˜ê°•: {left['drop_detected']}]")
if "Right" in result_data:
    right = result_data["Right"]
    print(f"[Right] y ë³€í™”ëŸ‰: {right['y_diffs']} â†’ í•˜ê°•: {right['drop_detected']}]")
print(f"ğŸ” ìµœì¢… íŒì • ê²°ê³¼: {result_data['final_diagnosis']}")
